{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gJc3tuJ2sxq5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import seaborn as sns### visualizations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "from datetime import datetime\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
        "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
        "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
        "                                     RandomContrast, Rescaling, Resizing, Reshape, LeakyReLU)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
        "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
        "from tensorflow.keras.regularizers import L2, L1\n",
        "from tensorflow.keras.initializers import RandomNormal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iN1_O3AxLXA"
      },
      "source": [
        "# *Dataset Download*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjUvmyzJs7U2",
        "outputId": "91ff16a7-9894-4f5b-e13c-105a121a6e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/huanghanchina/pascal-voc-2012\n",
            "License(s): DbCL-1.0\n",
            "pascal-voc-2012.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d huanghanchina/pascal-voc-2012"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OpT7krJas7RG"
      },
      "outputs": [],
      "source": [
        "val_list=['2007_000027.jpg','2007_000032.jpg','2007_000033.jpg','2007_000039.jpg','2007_000042.jpg','2007_000061.jpg',\n",
        "          '2007_000063.jpg','2007_000068.jpg','2007_000121.jpg','2007_000123.jpg','2007_000129.jpg','2007_000170.jpg',\n",
        "          '2007_000175.jpg','2007_000187.jpg','2007_000241.jpg','2007_000243.jpg','2007_000250.jpg','2007_000256.jpg',\n",
        "          '2007_000272.jpg','2007_000323.jpg','2007_000332.jpg','2007_000333.jpg','2007_000346.jpg','2007_000363.jpg',\n",
        "          '2007_000364.jpg','2007_000392.jpg','2007_000423.jpg','2007_000452.jpg','2007_000464.jpg','2007_000480.jpg',\n",
        "          '2007_000491.jpg','2007_000504.jpg','2007_000515.jpg','2007_000528.jpg','2007_000529.jpg','2007_000549.jpg',\n",
        "          '2007_000559.jpg','2007_000572.jpg','2007_000584.jpg','2007_000629.jpg','2007_000636.jpg','2007_000645.jpg',\n",
        "          '2007_000648.jpg','2007_000661.jpg','2007_000663.jpg','2007_000664.jpg','2007_000676.jpg','2007_000713.jpg',\n",
        "          '2007_000720.jpg','2007_000727.jpg','2007_000733.jpg','2007_000738.jpg','2007_000762.jpg','2007_000768.jpg',\n",
        "          '2007_000783.jpg','2007_000793.jpg','2007_000799.jpg','2007_000804.jpg','2007_000807.jpg','2007_000822.jpg',\n",
        "          '2007_001299.jpg','2007_001311.jpg','2007_001321.jpg','2007_001340.jpg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEFJ7fD_s7Gc",
        "outputId": "79ec1716-3332-4f6e-b237-30c6765c3b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/pascal-voc-2012.zip\n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000027.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000032.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000033.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000039.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000042.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000061.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000063.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000068.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000121.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000123.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000129.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000170.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000175.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000187.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000241.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000243.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000250.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000256.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000272.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000323.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000332.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000333.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000346.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000363.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000364.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000392.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000423.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000452.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000464.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000480.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000491.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000504.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000515.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000528.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000529.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000549.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000559.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000572.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000584.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000629.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000636.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000645.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000648.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000661.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000663.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000664.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000676.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000713.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000720.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000727.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000733.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000738.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000762.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000768.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000783.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000793.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000799.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000804.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000807.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_000822.xml  \n",
            "replace /content/dataset/VOC2012/Annotations/2007_000830.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_001299.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_001311.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_001321.xml  \n",
            "  inflating: /content/dataset/VOC2012/Annotations/2007_001340.xml  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000027.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000032.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000033.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000039.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000042.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000061.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000063.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000068.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000121.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000123.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000129.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000170.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000175.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000187.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000241.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000243.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000250.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000256.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000272.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000323.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000332.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000333.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000346.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000363.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000364.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000392.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000423.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000452.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000464.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000480.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000491.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000504.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000515.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000528.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000529.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000549.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000559.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000572.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000584.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000629.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000636.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000645.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000648.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000661.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000663.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000664.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000676.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000713.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000720.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000727.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000733.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000738.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000762.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000768.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000783.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000793.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000799.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000804.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000807.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_000822.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_001299.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_001311.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_001321.jpg  \n",
            "  inflating: /content/dataset/VOC2012/JPEGImages/2007_001340.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/pascal-voc-2012.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_voAdxus7DK",
        "outputId": "b1b415ef-9692-46d3-eab3-a5cd8ec2a2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "train_images='/content/dataset/VOC2012/JPEGImages/'\n",
        "train_maps='/content/dataset/VOC2012/Annotations/'\n",
        "\n",
        "val_images='/content/dataset/VOC2012/ValJPEGImages/'\n",
        "val_maps='/content/dataset/VOC2012/ValAnnotations/'\n",
        "\n",
        "classes=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable',\n",
        "         'dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
        "\n",
        "B=2\n",
        "N_CLASSES=len(classes)\n",
        "H,W =224,224\n",
        "SPLIT_SIZE=H//32\n",
        "print(SPLIT_SIZE)\n",
        "N_EPOCHS=135\n",
        "BATCH_SIZE=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmaI_9J1s7Au",
        "outputId": "b95dbc3c-102a-4e3b-904f-26ac1df51485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/dataset/VOC2012/ValJPEGImages/’: File exists\n",
            "mkdir: cannot create directory ‘/content/dataset/VOC2012/ValAnnotations/’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/dataset/VOC2012/ValJPEGImages/\n",
        "!mkdir /content/dataset/VOC2012/ValAnnotations/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wEEMOej-s68w"
      },
      "outputs": [],
      "source": [
        "for name in val_list:\n",
        "  shutil.move(train_maps+name[:-3]+\"xml\", val_maps+name[:-3]+\"xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mZfL99Dps663"
      },
      "outputs": [],
      "source": [
        "for name in val_list:\n",
        "  shutil.move(train_images+name, val_images+name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YCV21RcxWlQ"
      },
      "source": [
        "# *Data Preparation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u9DfEdYMs65L"
      },
      "outputs": [],
      "source": [
        "# ✔ Reads an XML file (likely in Pascal VOC format).\n",
        "# ✔ Extracts image size (width, height).\n",
        "# ✔ Finds objects and their bounding boxes.\n",
        "# ✔ Normalizes bounding box coordinates.\n",
        "# ✔ Maps class names to numerical labels.\n",
        "# ✔ Returns the result as a TensorFlow tensor.\n",
        "def preprocess_xml(filename):\n",
        "  tree = ET.parse(filename)# Parse the XML file into an ElementTree object\n",
        "  root = tree.getroot()# Get the root element of the XML\n",
        "  #Extract Image Dimensions\n",
        "  size_tree = root.find('size')\n",
        "  height = float(size_tree.find('height').text)\n",
        "  width = float(size_tree.find('width').text)\n",
        "  bounding_boxes=[]\n",
        "  for object_tree in root.findall('object'):\n",
        "    for bounding_box in object_tree.iter('bndbox'):#Extract Bounding Box Coordinates\n",
        "      xmin = (float(bounding_box.find('xmin').text))\n",
        "      ymin = (float(bounding_box.find('ymin').text))\n",
        "      xmax = (float(bounding_box.find('xmax').text))\n",
        "      ymax = (float(bounding_box.find('ymax').text))\n",
        "      break\n",
        "    class_name = object_tree.find('name').text\n",
        "    class_dict={classes[i]:i for i in range(len(classes))}\n",
        "    bounding_box = [\n",
        "        (xmin+xmax)/(2*width),(ymin+ymax)/(2*height),(xmax-xmin)/width,#Normalize Bounding Box Coordinates\n",
        "        (ymax-ymin)/height,class_dict[class_name]]\n",
        "    bounding_boxes.append(bounding_box)\n",
        "  return tf.convert_to_tensor(bounding_boxes)#Converts the list of bounding boxes into a TensorFlow tensor for further processing in deep learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ7saKGcs55e",
        "outputId": "7af19e2d-cff9-4f8b-f557-a9b53897d53c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 0.479     ,  0.4644128 ,  0.542     ,  0.37366548,  0.        ],\n",
              "       [ 0.33      ,  0.37544483,  0.128     ,  0.12455516,  0.        ],\n",
              "       [ 0.408     ,  0.727758  ,  0.036     ,  0.17437722, 14.        ],\n",
              "       [ 0.07      ,  0.7597865 ,  0.036     ,  0.17437722, 14.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocess_xml(val_maps+\"2007_000032.xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RK4DjVQQtq-h"
      },
      "outputs": [],
      "source": [
        "def generate_output(bounding_boxes):\n",
        "  output_label=np.zeros((SPLIT_SIZE,SPLIT_SIZE,N_CLASSES+5))\n",
        "  for b in range(len(bounding_boxes)):\n",
        "    #Compute Grid Cell Coordinates\n",
        "    grid_x=bounding_boxes[...,b,0]*SPLIT_SIZE\n",
        "    grid_y=bounding_boxes[...,b,1]*SPLIT_SIZE\n",
        "    i=int(grid_x)\n",
        "    j=int(grid_y)\n",
        "\n",
        "    output_label[i,j,0:5]=[1.,grid_x%1,grid_y%1,bounding_boxes[...,b,2],bounding_boxes[...,b,3]]\n",
        "    output_label[i,j,5+int(bounding_boxes[...,b,4])]=1.\n",
        "\n",
        "  return tf.convert_to_tensor(output_label,tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-65fIWhtt31",
        "outputId": "a95b6b50-4e05-4968-cb8f-1071032dc41c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
              "array([1.        , 0.35299993, 0.25088978, 0.542     , 0.37366548,\n",
              "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_output(preprocess_xml(val_maps+\"2007_000032.xml\"),)[3][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zt4R2oatwXs",
        "outputId": "8241e8dd-e5fa-400a-b9fb-4840f7c2d32f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17061 17061\n",
            "64 64\n"
          ]
        }
      ],
      "source": [
        "# convert xml to jpg\n",
        "# Used in object detection training (e.g., YOLO, Faster R-CNN, SSD).\n",
        "im_paths=[]\n",
        "xml_paths=[]\n",
        "\n",
        "val_im_paths=[]\n",
        "val_xml_paths=[]\n",
        "\n",
        "\n",
        "for i in os.listdir(train_maps):\n",
        "\n",
        "  im_paths.append(train_images+i[:-3]+'jpg')\n",
        "  xml_paths.append(train_maps+i)\n",
        "\n",
        "for i in os.listdir(val_maps):\n",
        "\n",
        "  val_im_paths.append(val_images+i[:-3]+'jpg')\n",
        "  val_xml_paths.append(val_maps+i)\n",
        "\n",
        "print(len(im_paths),len(xml_paths))\n",
        "print(len(val_im_paths),len(val_xml_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "51ICgesptzNN"
      },
      "outputs": [],
      "source": [
        "train_dataset=tf.data.Dataset.from_tensor_slices((im_paths,xml_paths))\n",
        "val_dataset=tf.data.Dataset.from_tensor_slices((val_im_paths,val_xml_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZFdZx0lt2SN",
        "outputId": "fdcdc7bd-066d-441c-eef5-b812b1fb64ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'/content/dataset/VOC2012/ValJPEGImages/2007_000063.jpg'>, <tf.Tensor: shape=(), dtype=string, numpy=b'/content/dataset/VOC2012/ValAnnotations/2007_000063.xml'>)\n"
          ]
        }
      ],
      "source": [
        "for i in val_dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "G3A8ZdK_t4vb"
      },
      "outputs": [],
      "source": [
        "# ✔ Loads & preprocesses an image for training.\n",
        "# ✔ Extracts bounding boxes from an XML annotation file.\n",
        "# ✔ Returns both as TensorFlow tensors for model training.\n",
        "def get_imbboxes(im_path,xml_path):\n",
        "  img=tf.io.decode_jpeg(tf.io.read_file(im_path))\n",
        "  img=tf.cast(tf.image.resize(img, [H,W]),dtype=tf.float32)\n",
        "\n",
        "  bboxes=tf.numpy_function(func=preprocess_xml, inp=[xml_path], Tout=tf.float32)\n",
        "  return img,bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K9QF2s2ot7Ft"
      },
      "outputs": [],
      "source": [
        "train_dataset=train_dataset.map(get_imbboxes)\n",
        "val_dataset=val_dataset.map(get_imbboxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luy5xKFrt-5z",
        "outputId": "7b4fa7c0-8b84-4fb2-cb0f-be1991b78080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(224, 224, 3) tf.Tensor(\n",
            "[[ 0.746       0.564       0.104       0.17866667  1.        ]\n",
            " [ 0.742       0.492       0.096       0.216      14.        ]], shape=(2, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for i,j in train_dataset.skip(2):\n",
        "  print(i.shape,j)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpAyOx5ZuAqY",
        "outputId": "dca70ae5-21a7-4ad9-bc2c-a1bcd6c118ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv2.imwrite('out_1.jpg',np.array(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xfEPV1qNuBwy"
      },
      "outputs": [],
      "source": [
        "transforms = A.Compose([\n",
        "    A.Resize(H,W),\n",
        "    A.RandomCrop(\n",
        "         width=np.random.randint(int(0.9*W),W),\n",
        "         height=np.random.randint(int(0.9*H),H), p=0.5),\n",
        "    A.RandomScale(scale_limit=0.1, interpolation=cv2.INTER_LANCZOS4,p=0.5),\n",
        "    A.HorizontalFlip(p=0.5,),\n",
        "    A.Resize(H,W),\n",
        "\n",
        "], bbox_params=A.BboxParams(format='yolo', ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uxSzv8vLuBtG"
      },
      "outputs": [],
      "source": [
        "def aug_albument(image,bboxes):\n",
        "  augmented=transforms(image=image,bboxes=bboxes)\n",
        "  return [tf.convert_to_tensor(augmented[\"image\"],dtype=tf.float32),\n",
        "          tf.convert_to_tensor(augmented[\"bboxes\"],dtype=tf.float32)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EuVA2yIkuBrB"
      },
      "outputs": [],
      "source": [
        "# ✔ Uses Albumentations for image & bounding box augmentation.\n",
        "# ✔ Ensures bounding boxes stay aligned after transformations.\n",
        "# ✔ Uses tf.numpy_function to run NumPy-based augmentation inside TensorFlow.\n",
        "# ✔ Returns augmented image & updated bounding boxes\n",
        "def process_data(image,bboxes):\n",
        "    aug= tf.numpy_function(func=aug_albument, inp=[image,bboxes], Tout=(tf.float32,tf.float32))\n",
        "    return aug[0],aug[1]\n",
        "# aug[0] → The augmented image.\n",
        "# aug[1] → The transformed bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "e13YGdgHuBpD"
      },
      "outputs": [],
      "source": [
        "train_dataset=train_dataset.map(process_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgxIUV77uBnT",
        "outputId": "190e454b-c9e6-453d-de6c-2c1c3441c2fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(224, 224, 3) tf.Tensor(\n",
            "[[ 0.746       0.564       0.10399997  0.17866668  1.        ]\n",
            " [ 0.742       0.492       0.09599996  0.21600002 14.        ]], shape=(2, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for i,j in train_dataset.skip(2):\n",
        "  print(i.shape,j)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeJQRgipuQVe",
        "outputId": "7be8765b-c5bf-46f7-d1fd-37740083f5e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv2.imwrite('out_2.jpg',np.array(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_T0vKOE6uSkU"
      },
      "outputs": [],
      "source": [
        "def preprocess_augment(img,y):\n",
        "  img = tf.image.random_brightness(img, max_delta=50.)\n",
        "  img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "  img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "  #img = tf.image.random_hue(img, max_delta=0.5 )\n",
        "  img = tf.clip_by_value(img, 0, 255)\n",
        "  labels=tf.numpy_function(func=generate_output, inp=[y], Tout=(tf.float32))\n",
        "  return img,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JGUrhZkFuU-U"
      },
      "outputs": [],
      "source": [
        "def preprocess(img,y):\n",
        "  img = tf.cast(tf.image.resize(img, size=[H, W]), dtype=tf.float32)\n",
        "\n",
        "  labels=tf.numpy_function(func=generate_output, inp=[y], Tout=(tf.float32))\n",
        "  return img,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LznRUNUEuZGX"
      },
      "outputs": [],
      "source": [
        "train_dataset=train_dataset.map(preprocess_augment)\n",
        "val_dataset=val_dataset.map(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xIMSwKg2uZBu"
      },
      "outputs": [],
      "source": [
        "train_dataset=(\n",
        "  train_dataset.\n",
        "  batch(BATCH_SIZE).\n",
        "  prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YgM0dCGCuY_k"
      },
      "outputs": [],
      "source": [
        "val_dataset=(\n",
        "  val_dataset.\n",
        "  batch(BATCH_SIZE).\n",
        "  prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlLewoILuY9k",
        "outputId": "ab30bb49-1c16-43a4-f011-49acb5884782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3) tf.Tensor(\n",
            "[[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [1.         0.5099713  0.48500794 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [1.         0.37443048 0.36089754 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [1.         0.7790001  0.3026665  ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.4869998  0.67866695 ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [1.         0.9490001  0.3680001  ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.411      0.8293334  ... 0.         0.\n",
            "    1.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [1.         0.3060001  0.89066684 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.34991255 0.42520988 ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.         0.5961378  0.65467316 ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], shape=(32, 7, 7, 25), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "for i,j in train_dataset.take(1):\n",
        "  print(i.shape,j)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9bEtQouuY7r",
        "outputId": "e3d87d47-1297-4b12-8d73-38cabc23e7a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv2.imwrite('out_3.jpg',np.array(i[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXv24gHxm-E"
      },
      "source": [
        "# *Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vSj7Ut7rupND"
      },
      "outputs": [],
      "source": [
        "NUM_FILTERS=512\n",
        "OUTPUT_DIM=N_CLASSES+5*B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LLvyX_rNutFX"
      },
      "outputs": [],
      "source": [
        "#The base model will act as a feature extractor.\n",
        "#base_model = tf.keras.applications.resnet50.ResNet50(\n",
        "base_model=tf.keras.applications.efficientnet.EfficientNetB1(\n",
        "    weights='imagenet',#Loads weights pre-trained on ImageNet\n",
        "    input_shape=(H,W,3),#Ensures that the model is compatible with your dataset.\n",
        "    include_top=False,#Excludes the final classification layer (fully connected \"top\" layers).\n",
        ")\n",
        "base_model.trainable=False#Prevents updates to the base model's weights during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FJydrmHcXGcQ"
      },
      "outputs": [],
      "source": [
        "IM_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "ocbl7zxfutZ4",
        "outputId": "102b4aa6-05b2-4902-83b0-f1d6afbdf619"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,575,239</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,898,752</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1470</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">754,110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb1 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m6,575,239\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m5,898,752\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m12,845,568\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1470\u001b[0m)                │         \u001b[38;5;34m754,110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m30\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,161,285</span> (126.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,161,285\u001b[0m (126.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,581,950</span> (101.40 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,581,950\u001b[0m (101.40 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,579,335</span> (25.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,579,335\u001b[0m (25.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model=tf.keras.Sequential([\n",
        "  #InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "  base_model,\n",
        "  Conv2D(NUM_FILTERS,(3,3), padding = 'same',kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Conv2D(NUM_FILTERS,(3,3),padding = 'same',kernel_initializer='he_normal',),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Flatten(),\n",
        "\n",
        "  Dense(NUM_FILTERS,kernel_initializer='he_normal',),\n",
        "  BatchNormalization(),\n",
        "  LeakyReLU(alpha=0.1),\n",
        "\n",
        "  Dropout(0.5),\n",
        "\n",
        "  Dense(SPLIT_SIZE*SPLIT_SIZE*OUTPUT_DIM,activation='sigmoid'),\n",
        "\n",
        "  Reshape((SPLIT_SIZE,SPLIT_SIZE,OUTPUT_DIM)),\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GPiiR7OOuw5w"
      },
      "outputs": [],
      "source": [
        "def compute_iou(boxes1, boxes2):\n",
        "    boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
        "                         boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
        "                         boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
        "                         boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
        "                        axis=-1)\n",
        "\n",
        "    boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
        "                         boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
        "                         boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
        "                         boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
        "                        axis=-1)\n",
        "    lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
        "    rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
        "\n",
        "    intersection = tf.maximum(0.0, rd - lu)\n",
        "    inter_square = intersection[..., 0] * intersection[..., 1]\n",
        "\n",
        "    square1 = boxes1[..., 2] * boxes1[..., 3]\n",
        "    square2 = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
        "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lmM1uMUru1-a"
      },
      "outputs": [],
      "source": [
        "def difference(x,y):\n",
        "  return tf.reduce_sum(tf.square(y-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "G52nQd7wu4On"
      },
      "outputs": [],
      "source": [
        "def yolo_loss(y_true, y_pred):\n",
        "  target = y_true[...,0]\n",
        "\n",
        "  ###################### OBject Loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred, tf.where(target[:]==1))\n",
        "  y_target_extract = tf.gather_nd(y_true, tf.where(target[:]==1))\n",
        "\n",
        "  rescaler = tf.where(target[:]==1)*SPLIT_SIZE\n",
        "  upscaler_1 = tf.concat([rescaler[:,1:],tf.zeros([len(rescaler),2], dtype=tf.int64)],axis=-1)\n",
        "\n",
        "  target_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
        "                       repeats=[len(rescaler)], axis=0)*tf.cast(y_target_extract[...,1:5], dtype = tf.float32)\n",
        "  pred_1_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
        "                      repeats=[len(rescaler)], axis=0)*tf.cast(y_pred_extract[...,1:5], dtype = tf.float32)\n",
        "  pred_2_upscaler_2 = tf.repeat([[float(SPLIT_SIZE),float(SPLIT_SIZE),H,W]],\n",
        "                      repeats=[len(rescaler)], axis=0)*tf.cast(y_pred_extract[...,6:10], dtype = tf.float32)\n",
        "\n",
        "  target_orig = tf.cast(upscaler_1, dtype = tf.float32)+target_upscaler_2\n",
        "  pred_1_orig = tf.cast(upscaler_1, dtype = tf.float32)+pred_1_upscaler_2\n",
        "  pred_2_orig = tf.cast(upscaler_1, dtype = tf.float32)+pred_2_upscaler_2\n",
        "\n",
        "  mask =tf.cast(tf.math.greater(compute_iou(target_orig,pred_2_orig),\n",
        "                                         compute_iou(target_orig,pred_1_orig)),dtype=tf.int32)\n",
        "\n",
        "  y_pred_joined=tf.transpose(tf.concat([tf.expand_dims(y_pred_extract[...,0],axis=0),\n",
        "                        tf.expand_dims(y_pred_extract[...,5],axis=0)],axis=0))\n",
        "\n",
        "  obj_pred = tf.gather_nd(y_pred_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "\n",
        "  object_loss = difference(tf.cast(obj_pred,dtype =tf.float32)\n",
        "                            ,tf.cast(tf.ones([len(rescaler)]),dtype=tf.float32))\n",
        "\n",
        "  ####################### For No object\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,0:B*5], tf.where(target[:]==0))\n",
        "  y_target_extract = tf.zeros(len(y_pred_extract))\n",
        "\n",
        "  no_object_loss_1 = difference(tf.cast(y_pred_extract[...,0],dtype =tf.float32)\n",
        "                            ,tf.cast(y_target_extract,dtype=tf.float32))\n",
        "\n",
        "  no_object_loss_2 = difference(tf.cast(y_pred_extract[...,5],dtype =tf.float32)\n",
        "                            ,tf.cast(y_target_extract,dtype=tf.float32))\n",
        "\n",
        "  no_object_loss = no_object_loss_1+no_object_loss_2\n",
        "\n",
        "  ######################## For OBject class loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,10:],tf.where(target[:]==1))\n",
        "  class_extract = tf.gather_nd(y_true[...,5:],tf.where(target[:]==1))\n",
        "\n",
        "  class_loss = difference(tf.cast(y_pred_extract,dtype =tf.float32)\n",
        "                                ,tf.cast(class_extract,dtype=tf.float32))\n",
        "\n",
        "  ######################### For object bounding box loss\n",
        "  y_pred_extract = tf.gather_nd(y_pred[...,0:B*5], tf.where(target[:]==1))\n",
        "  centre_joined=tf.stack([y_pred_extract[...,1:3],y_pred_extract[...,6:8]],axis=1)\n",
        "  centre_pred = tf.gather_nd(centre_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "  centre_target = tf.gather_nd(y_true[...,1:3], tf.where(target[:]==1))\n",
        "\n",
        "  centre_loss = difference(centre_pred,centre_target)\n",
        "\n",
        "  size_joined=tf.stack([y_pred_extract[...,3:5],y_pred_extract[...,8:10]],axis=1)\n",
        "\n",
        "  size_pred = tf.gather_nd(size_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "  size_target = tf.gather_nd(y_true[...,3:5], tf.where(target[:]==1))\n",
        "\n",
        "  size_loss = difference(tf.math.sqrt(tf.math.abs(size_pred)),tf.math.sqrt(tf.math.abs(size_target)))\n",
        "  box_loss = centre_loss+size_loss\n",
        "\n",
        "  lambda_coord = 5.0\n",
        "  lambda_no_obj = 0.5\n",
        "\n",
        "  loss = object_loss + (lambda_no_obj*no_object_loss)+ tf.cast(lambda_coord*box_loss,dtype=tf.float32)+ tf.cast(class_loss,dtype=tf.float32)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "M74lOYfMv6MP"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath=\"best.weights.h5\"\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "F42Fz9pZwBPe"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 40:\n",
        "    return 1e-3\n",
        "  elif epoch>=40 and epoch<80:\n",
        "    return 5e-4\n",
        "  else:\n",
        "    return 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OPNllsK3wBKO"
      },
      "outputs": [],
      "source": [
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jPcLnn2nwBIB"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss=yolo_loss,\n",
        "  optimizer=Adam(1e-3),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JGsm9th1wL1o"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "T9bukx9lwLyf"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "tQA4WXX_wIOb",
        "outputId": "035b7339-9071-41dd-8d7a-2c5f9558a88d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/135\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=True\n  • mask=None",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-aff0f6093294>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=True\n  • mask=None"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=val_dataset,\n",
        "  verbose=1,\n",
        "  epochs=135,\n",
        "  callbacks = [lr_callback,callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsWqG0If806-",
        "outputId": "f6b7cfb6-3ed6-4a6a-ebe9-d36654ed0e29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDCL1WMoX0tg",
        "outputId": "b149a89e-ac2a-41b8-fff1-64af5622a225"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, None), dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6mOKsm5bPb4",
        "outputId": "81ab60d3-bf8d-4e8f-a267-c6691eb8ac56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 7, 7, 25)\n"
          ]
        }
      ],
      "source": [
        "for data, labels in train_dataset.take(1):\n",
        "  print(data.shape)\n",
        "  print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-kPDwQVkeB_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
